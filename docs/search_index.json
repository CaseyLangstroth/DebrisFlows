[["index.html", "Constraining Erosion of Post-Wildfire Debris Flow Fans Chapter 1 About", " Constraining Erosion of Post-Wildfire Debris Flow Fans Casey Langstroth 2023-04-24 Chapter 1 About This is a bookdown website for my thesis project and for the final project for RDS2023. Each chapter documents code and data management for each step along the way. "],["database-structure.html", "Chapter 2 Database Structure: 2.1 Code for designing and building my database structure in R", " Chapter 2 Database Structure: Figure 2.1: database structure 2.1 Code for designing and building my database structure in R 2.1.0.1 Connecting and building the db library(DBI) df_db = dbConnect(RSQLite::SQLite(), &#39;df_db&#39;) 2.1.1 Creating tables in db #DF ID table dbExecute(df_db, &quot;create table df_ID ( Site varchar(50) NOT NULL primary key, Fire varchar(50) NOT NULL, Lat double, Long double);&quot;) #DF geospatial volume estimates dbExecute(df_db, &quot;create table df_volume( DF_ID varchar(5) primary key, Site varchar(50) NOT NULL, EstInt double, t_0 double, t_1 double, t_2 double, t_3 double, t_4 double, t_5 double, t_6 double, t_7 double, t_8 double, t_9 double, t_10 double, foreign key (Site) references df_ID(Site));&quot;) #df grain size distributions (modelled and observed) dbExecute(df_db, &quot;create table df_gsd( DF_ID varchar(5) primary key, Site varchar(50) NOT NULL, initialsub_D16phi double, initialsub_D50phi double, initialsub_D84phi double, initialsub_D16mm double, initialsub_D50mm double, initialsub_D84mm double, obssur_D16mm double, obssur_D50mm double, obssur_D84mm double, obssub_D16mm double, obssub_D50mm double, obssub_D84mm double, foreign key (Site) references df_ID(Site)); &quot;) #geospatial debris flow morphology dbExecute(df_db, &quot;create table df_morphology( DF_ID varchar(5) primary key, site_name varchar(50) NOT NULL, runout_L double, RF_angle double, int_vol double, foreign key (site_name) references df_ID(site_name));&quot;) #geospatial reach morphology dbExecute(df_db, &quot;create table reach_morphology( reach_ID integer check(reach_ID in (1,2,3)), DF_name varchar(50) primary key, DF_ID varchar(5), site_ID varchar(10) generated always as (DF_ID + &#39;_&#39; + reach_ID) stored, stream_class char(1) check(stream_class in (&#39;P&#39;, &#39;I&#39;)), reach_lengthm integer, valley_widthm double, foreign key (DF_ID) references df_morphology(DF_ID));&quot;) #geospatial/modeled channel morphology dbExecute(df_db, &quot;create table channel_morphology( DF_ID varchar(5) primary key, channel_ID varchar(10), IMP_BFWm double, IMP_BFDm double, flow_depthm double, D50phi_Snyder double, D50mm_Snyder double, river_lengthm double, sinuosity double, usdakm2 double, gradient double, slope_deg double, q2m3 double, q5m3 double, q10m3 double, q50m3 double, q100m3 double, q500m3 double, foreign key (channel_ID) references reach_morphology(site_ID));&quot;) #geospatial subcatchment morphology dbExecute(df_db, &quot;create table subcatchment_morphology( catch_id integer primary key autoincrement, DF_ID varchar(5), drainage_areakm2 double, relief double, Cp2008 double, Cp2011 double, Cp2016 double, Sp23 double, Mean_Elevation double, MgO double, Rd double, WI double, CS double, Om double, Ro double, AnnP double, T double, K double, HC double, S23_Areakm2 double, Bmh_Areakm2 double, Channel_Devlp char(1) check(Channel_Devlp in (&#39;Y&#39;,&#39;N&#39;)), foreign key (DF_ID) references reach_morphology(DF_ID));&quot;) 2.1.2 Import csv to dbtables #first, read csvs sites = read.csv(&#39;//data//data_sheets//Site_Locations.csv&#39;, header = T) df_volumes = read.csv(&#39;//data//data_sheets//processed_summary_data//Gross_Summary_Vol_tdf.csv&#39;, header = T, na.strings = &#39; &#39;) df_gsd = read.csv(&#39;//data//data_sheets//processed_summary_data//df_gsd.csv&#39;, header = T, na.strings = &#39; &#39;) df_morphology = read.csv(&#39;//data//data_sheets//processed_summary_data//df_morphology.csv&#39;, header = T, na.strings = &#39; &#39;) reach_morphology = read.csv(&#39;//data//data_sheets//processed_summary_data//reach_morphology.csv&#39;, header = T, na.strings = &#39; &#39;) channel_morphology = read.csv(&#39;//data//data_sheets//processed_summary_data//channel_morphology.csv&#39;, header = T, na.strings = &#39; &#39;) subcatch_morphology = read.csv(&#39;//data//data_sheets//processed_summary_data//subcatchment_morphology.csv&#39;, header = T, na.strings = &#39; &#39;) # import csv into tables (for completed tables) dbWriteTable(df_db, &#39;df_ID&#39;, sites, append = TRUE) dbWriteTable(df_db, &#39;df_volume&#39;, df_volumes, append = TRUE) dbWriteTable(df_db, &#39;df_gsd&#39;, df_gsd, append = TRUE) "],["volume-plots.html", "Chapter 3 Volume Plots 3.1 Read the CSV 3.2 Volume Compare Plots", " Chapter 3 Volume Plots Building the volume plots for debris flow volume over time 3.1 Read the CSV ## Site EstInt t_0 t_1 t_2 t_3 t_4 t_5 t_6 t_7 ## 1 Brian Head 5A 1537.700 1537.700 1281.108 NA 1210.232 NA NA NA NA ## 2 Brian Head 3 3267.823 3230.050 3049.005 NA 3026.695 NA NA NA NA ## 3 Dollar Ridge 1A 13846.132 12873.775 12376.495 NA 12197.908 NA NA NA NA ## 4 Dollar Ridge 2A 1128.266 1056.268 1104.269 NA 999.490 NA NA NA NA ## 5 Dollar Ridge 3A 5982.974 5982.974 5982.974 NA 5982.974 NA NA NA NA ## 6 Dollar Ridge 4A 3861.250 3388.531 3322.835 NA 3217.984 NA NA NA NA ## t_8 t_9 t_10 ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA NA ## 4 NA NA NA ## 5 NA NA NA ## 6 NA NA NA 3.1.1 Edit the column names and create new percent table object colnames(gross_sum_tdf) = c(&#39;Site&#39;,&#39;EstInt&#39;, &#39;0&#39;, &#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;,&#39;10&#39;) gross_sum_t_perc = gross_sum_tdf 3.1.2 change the percent the EstInt column (2) to 100% gross_sum_t_perc[,2] = 100 Get percent change l1 = list(3:13)#number of columns for (i in l1){ gross_sum_t_perc[,i] = round((gross_sum_tdf[,i]/gross_sum_tdf[,2]*100),1) } 3.1.3 Extract the debris flows per fire for seperate plots brian_head = gross_sum_t_perc[(1:2),] dollar_ridge = gross_sum_t_perc[(3:10),] twitchell = gross_sum_t_perc[(11:31),] pole_creek = gross_sum_t_perc[(32:34),] seeley= gross_sum_t_perc[(35:40),] shingle= gross_sum_t_perc[(41:42),] trail_mountain = gross_sum_t_perc[(43:47),] clay_springs = gross_sum_t_perc[48:52,] 3.1.4 pivot longer (t for tibble) library(magrittr) #for piping library(tidyr) #for tibble ## ## Attaching package: &#39;tidyr&#39; ## The following object is masked from &#39;package:magrittr&#39;: ## ## extract library(ggplot2) #for plotting brian_head_t = brian_head %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) dollar_ridge_t = dollar_ridge %&gt;%pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) twitchell_t = twitchell %&gt;% pivot_longer(cols = EstInt:&#39;10&#39;, names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) pole_creek_t = pole_creek %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) seeley_t = seeley %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) shingle_t = shingle %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) clay_springs_t = clay_springs %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) trail_mountain_t = trail_mountain %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) gross_sum_t_perc_t = gross_sum_t_perc %&gt;% pivot_longer(cols = EstInt:&#39;10&#39; , names_to = &#39;Time&#39;, values_to = &#39;Volume&#39;) gross_sum_t_perc_t$Fire = NA 3.1.5 Add in fire name gross_sum_t_perc_t[c(1:24),4] = &#39;Brian Head&#39; gross_sum_t_perc_t[c(25:120),4] = &#39;Dollar Ridge&#39; gross_sum_t_perc_t[c(121:372),4]= &#39;Twitchell&#39; gross_sum_t_perc_t[c(373:408),4] = &#39;Pole Creek&#39; gross_sum_t_perc_t[c(409:480),4] = &#39;Seeley&#39; gross_sum_t_perc_t[c(481:504),4] = &#39;Shingle&#39; gross_sum_t_perc_t[c(505:564),4] = &#39;Trail Mountain&#39; gross_sum_t_perc_t[c(565:624),4] = &#39;Clay Springs&#39; 3.1.6 plots Gross Volume All ## Saving 7 x 5 in image ## Saving 7 x 5 in image Twitchell Fire Brian Head Fire ## Warning: Removed 16 rows containing missing values (geom_point). Dollar Ridge Fire Pole Creek Fire Seeley Fire Shingle Fire Clay Springs Fire Trail Mountain Fire 3.2 Volume Compare Plots ## Site obs_vol initial_vol_est obs_vol_low obs_vol_high X2020_reg ## 1 Brianhead 1 65 97.5 73.125 131.625 114.4951 ## 2 Brianhead 2 500 625.0 468.750 843.750 283.9000 ## 3 Brianhead 3 1500 1800.0 1350.000 2430.000 1009.5000 ## 4 Brianhead 4 380 532.0 399.000 718.200 411.4000 ## 5 Clay Springs 1 1050 1522.5 1141.875 2055.375 1866.0480 ## 6 Clay Springs 2 170 187.0 140.250 252.450 631.9028 ## int_reg int_vol_Wall ## 1 NA NA ## 2 1837.290 2287.9 ## 3 3267.823 1022.9 ## 4 753.100 1112.7 ## 5 NA NA ## 6 NA NA ## Warning: Ignoring unknown parameters: yintercept "],["comparing-against-volume-prediction-models.html", "Chapter 4 Comparing against Volume Prediction Models 4.1 Data organizing/building 4.2 Get Standard Deviations 4.3 Plots", " Chapter 4 Comparing against Volume Prediction Models To get an idea of potential accuracy of my estimates, I will compare them against current volume prediction models for those sub-catchments 4.1 Data organizing/building ## # A tibble: 6 Ã— 7 ## Site int_estimg int_vol_Wall int_volG14 ln_Wall ln_G14 ln_estint ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Brian Head 5A 1538. 1076. 3253. 6.98 8.09 7.34 ## 2 Brian Head 3 3268. 5224. 21612. 8.56 9.98 8.09 ## 3 Dollar Ridge 1A 13846. 2806. 6011. 7.94 8.70 9.54 ## 4 Dollar Ridge 2A 1128. 3524. 6557. 8.17 8.79 7.03 ## 5 Dollar Ridge 3A 5983. 2313. 1528. 7.75 7.33 8.70 ## 6 Dollar Ridge 4A 3861. 4571. 4606. 8.43 8.44 8.26 4.2 Get Standard Deviations recurrence interval risd = gartnervol[,-c(3)] risd$diff = NA rows = c(1:31) for (i in rows){ risd[i,4] = (risd[i,2]-risd[i,3]) } g14_out = boxplot.stats(risd$diff, coef = 1)$out g14_outind = which(risd$diff %in% c(g14_out)) risddev = sd(na.omit(risd$diff)) wall standard deviation wallsd = wall_vol[,-c(3)] wallsd$diff= NA rows = c(1:31) for (i in rows){ wallsd[i,4] = (wallsd[i,2]-wallsd[i,3]) } remove outlier wall_out = boxplot.stats(wallsd$diff)$out wall_outind = which(wallsd$diff %in% c(wall_out)) walldev = sd(na.omit(wallsd$diff)) standard deviation, all plots allsd = all[,-c(3)] allsd$diff = NA rows = c(1:62) for (i in rows){ allsd[i,4]= (allsd[i,2]- allsd[i,3]) } remove outlier out = boxplot.stats(allsd$diff)$out out_ind = which(allsd$diff %in% c(out)) all_nout = allsd[-c(out_ind),] alldev = sd(na.omit(all_nout$diff)) 4.3 Plots ## Warning: Duplicated aesthetics after name standardisation: ## Warning: Ignoring unknown parameters: ## Warning: Removed 8 rows containing missing values (geom_point). ## Warning: Duplicated aesthetics after name standardisation: ## Warning: Ignoring unknown parameters: ## Warning: Removed 7 rows containing missing values (geom_point). ### Plots for ln ## Warning: Duplicated aesthetics after name standardisation: ## Warning: Ignoring unknown parameters: ## Warning: Removed 3 rows containing missing values (geom_point). "],["grain-size-distribution-plots.html", "Chapter 5 Grain Size Distribution Plots", " Chapter 5 Grain Size Distribution Plots For now, this is just documentation of modeled grain sizes for the debris flow fans. I imagine eventually I will use these to compare between sites. ## DF_ID Fire est_D16..phi..2008 est_D16..phi..2011 est_D16..phi..2016 ## 1 BH5A Brian Head NA NA 0.6 ## 2 BH3 Brian Head NA NA -0.7 ## 3 DR1A Dollar Ridge NA NA 1.4 ## 4 DR2A Dollar Ridge NA NA 2.0 ## 5 DR3A Dollar Ridge NA NA 0.8 ## 6 DR4A Dollar Ridge NA NA 1.0 ## est_D50..phi. est_D84..phi. est_D84B..phi. ## 1 -4.5 -6.5 -9.5 ## 2 -4.1 -5.9 -9.3 ## 3 -4.2 -5.6 -9.5 ## 4 -4.2 -6.3 -9.5 ## 5 -2.9 -4.9 -9.4 ## 6 -2.9 -4.8 -9.4 ## â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€ ## âœ” tibble 3.1.8 âœ” dplyr 1.0.9 ## âœ” readr 2.1.2 âœ” stringr 1.4.0 ## âœ” purrr 0.3.4 âœ” forcats 0.5.1 ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€ ## âœ– tidyr::extract() masks magrittr::extract() ## âœ– dplyr::filter() masks stats::filter() ## âœ– dplyr::lag() masks stats::lag() ## âœ– purrr::set_names() masks magrittr::set_names() "],["some-possible-correlated-variables.html", "Chapter 6 Some possible correlated variables", " Chapter 6 Some possible correlated variables These are some very preliminary scatter plots for potential predictor and response variables. I still have data to gather :). Confinement Plot Accomodation Space Runout Percent of Valley Bottom Angle Plot Sinuosity Pre-fire Sinuosity Post-fire "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
